import tensorflow as tf

# X and Y data
x_train = [1,2,3]
y_train = [1,2,3]

#tensorflow 가 사용하는 variable. tensorflow가 자체적으로 학습하는, trainable한 variable
W=tf.Variable(tf.random_normal([1]), name='weight')
b=tf.Variable(tf.random_normal([1]), name='bias')

#Our hypothesis XW+b
hypothesis = x_train*W+b

#Cost/Loss function
#reduce_mean : 평균 내주는 function
cost=tf.reduce_mean(tf.square(hypothesis-y_train))

##Minimize(GradientDescent)
optimizer = tf.train.GradientDescentOptimizer(learning_rate=0.01)
train=optimizer.minimize(cost)

#graph 실행 위해 Session 만들기
#Launch the graph in a session.
sess=tf.Session()
#Initializes global variables in the graph(꼭 해줘야 함)
sess.run(tf.global_variables_initializer())

#Fit the line
for step in range(2001):
#train 실행
    sess.run(train)
    if step%20==0:
        print(step, sess.run(cost), sess.run(W), sess.run(b))

























import tensorflow as tf
#placeholder : 값을 필요할 때 던져준다
#값을 나중에 넘겨줄 수 있음.
a=tf.placeholder(tf.float32)
b=tf.placeholder(tf.float32)
adder_node=a+b     # + provides a shortcut for tf.add(a,b)

print(sess.run(adder_node, feed_dict={a:3, b:4.5}))
print(sess.run(adder_node, feed_dict={a:[1,3],b:[2,4]}))

# X=tf.placeholder(tf.float32, shape=[None] : 1차원 array이고 개수는 여러개가능 )